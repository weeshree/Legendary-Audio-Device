{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\weesh\\anaconda3\\lib\\site-packages\\serial\\__init__.py\n"
     ]
    }
   ],
   "source": [
    "import serial\n",
    "\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "print(serial.__file__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\weesh\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\weesh\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\weesh\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\weesh\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\weesh\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\weesh\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\weesh\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\weesh\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\weesh\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\weesh\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\weesh\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\weesh\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\weesh\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "corpus length: 452488\n",
      "total chars: 93\n",
      "{'\\n': 0, ' ': 1, '!': 2, '\"': 3, '#': 4, '%': 5, '&': 6, \"'\": 7, '(': 8, ')': 9, '*': 10, '+': 11, ',': 12, '-': 13, '.': 14, '/': 15, '0': 16, '1': 17, '2': 18, '3': 19, '4': 20, '5': 21, '6': 22, '7': 23, '8': 24, '9': 25, ':': 26, '<': 27, '=': 28, '>': 29, '?': 30, '@': 31, 'A': 32, 'B': 33, 'C': 34, 'D': 35, 'E': 36, 'F': 37, 'G': 38, 'H': 39, 'I': 40, 'J': 41, 'K': 42, 'L': 43, 'M': 44, 'N': 45, 'O': 46, 'P': 47, 'Q': 48, 'R': 49, 'S': 50, 'T': 51, 'U': 52, 'V': 53, 'W': 54, 'X': 55, 'Y': 56, 'Z': 57, '[': 58, '\\\\': 59, ']': 60, '^': 61, '_': 62, 'a': 63, 'b': 64, 'c': 65, 'd': 66, 'e': 67, 'f': 68, 'g': 69, 'h': 70, 'i': 71, 'j': 72, 'k': 73, 'l': 74, 'm': 75, 'n': 76, 'o': 77, 'p': 78, 'q': 79, 'r': 80, 's': 81, 't': 82, 'u': 83, 'v': 84, 'w': 85, 'x': 86, 'y': 87, 'z': 88, '{': 89, '|': 90, '}': 91, '~': 92}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "import io\n",
    "from keras.models import load_model\n",
    "\n",
    "model2 = load_model('my_model (2).h5')\n",
    "\n",
    "path = 'nottingham.txt'\n",
    "with io.open(path, encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "print('corpus length:', len(text))\n",
    "\n",
    "chars = sorted(list(set(text)))\n",
    "print('total chars:', len(chars))\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
    "\n",
    "print(char_indices)\n",
    "# cut the text in semi-redundant sequences of maxlen characters\n",
    "maxlen = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----- Generating text:\n"
     ]
    }
   ],
   "source": [
    "print()\n",
    "print('----- Generating text:')\n",
    "\n",
    "\n",
    "def sample(preds, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)\n",
    "\n",
    "start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "# for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
    "#     print('----- diversity:', diversity)\n",
    "\n",
    "#     generated = ''\n",
    "#     sentence = text[start_index: start_index + maxlen]\n",
    "#     generated += sentence\n",
    "#     print('----- Generating with seed: \"' + sentence + '\"')\n",
    "# #     sys.stdout.write(generated)\n",
    "\n",
    "#     for i in range(400):\n",
    "#         x_pred = np.zeros((1, maxlen, len(chars)))\n",
    "#         for t, char in enumerate(sentence):\n",
    "#             x_pred[0, t, char_indices[char]] = 1.\n",
    "\n",
    "#         preds = model2.predict(x_pred, verbose=0)[0]\n",
    "#         next_index = sample(preds, diversity)\n",
    "#         next_char = indices_char[next_index]\n",
    "\n",
    "#         sentence = sentence[1:] + next_char\n",
    "#         #print(i, next_char)\n",
    "# #         sys.stdout.write(next_char)\n",
    "# #         sys.stdout.flush()\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ESPSerial = serial.Serial('com4',115200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\weesh\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: RuntimeWarning: divide by zero encountered in log\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":Kerrs/Eric Foxley\n",
      "M:4/4\n",
      "L:1/4\n",
      "K:G\n",
      "P:A\n",
      "(2 g/2G/2e/2g/2|\\\n",
      "\"D\"f/2d/2f/2a/2 \"G\"g/2f/2g/2e/2|\"D\"f/2d/2f/2a/2 \"A7\"g/2e/2c/2e/2|\\\n",
      "\"D\"d/2c/2d/2B/2 A/2G/2F/2E/2|\"D\"D/2F/2A/2D/2 B/2D/2F/2D/2|\\\n",
      "\"G\"B/2G/2B/2d/2 g/2d/2B/2d/2|\"D7\"c/2d/2c/2A/2 c/2d/2c/2A/2|\\\n",
      "\"G\"B/2A/2G/2F/2 E/2D/2B|\"D\"AD/2F/2 DD/2F/2|\"G\"G/2B/2d/2B/2 \"A7\"e/2c/2A/2B/2|\\\n",
      "\"D\"dd d:|\n",
      "P:B\n",
      "f/2g/2|\"D\"af d3/2d/2|\"D\"AF Ad|\"A7\"c/2e/2c AF/2E/2|\"D\"D/2E/2F/2G/2 AB|DF/2G/2 FE|F3/2D/2 DD|\\\n",
      "FD-|FE A2|FA FA|\n",
      "\"G\"G/2F/2G/2B/2 d/2B/2G/2B/2|d/2B/2G/2B/2 d/2B/2A/2B/2|\\\n",
      "\"G\"G/2B/2G/2B/2 \"D\"A/2F/2D/2F/2|\\\n",
      "\"G\"G/2B/2\"D\"d/2A/2 \"G\"G/2A/2B/2d/2|\"C\"c/2A/2B/2G/2 \"D7\"A/2c/2B/2A/2|\\\n",
      "\"G\"G/2A/2B/2c/2 d/2e/2d/2c/2|\"G\"B/2d/2e/2f/2 g/2f/2e/2d/2|\\\n",
      "\"C\"c/2d/2e/2f/2 \"G\"g/2f/2g/2e/2|\\\n",
      "\"G\"d/2B/2e/2d/2 Bd/2c/2|\"G\"B/2G/2B/2d/2 gd|\"G\"B/2d/2e \"D\"dd/2c/2|\"G\"B/2d/2g/2d/2 \"C\"c/2d/2e/2f/2|\\\n",
      "\"G/d/2g/2f/2e/2 \"A7\"d/2c/2B/2A/2|\"D\"dd d:|\n",
      "P\n",
      "CHUNK (2g/2\n",
      "CHUNK G/2\n",
      "CHUNK e/2\n",
      "CHUNK g/2\n",
      "CHUNK ^f/2@\n",
      "CHUNK d/2\n",
      "CHUNK ^f/2\n",
      "CHUNK a/2\n",
      "CHUNK g/2\n",
      "CHUNK ^f/2\n",
      "CHUNK g/2\n",
      "CHUNK e/2\n",
      "CHUNK ^f/2@\n",
      "CHUNK d/2\n",
      "CHUNK ^f/2\n",
      "CHUNK a/2\n",
      "CHUNK g/2\n",
      "CHUNK e/2\n",
      "CHUNK c/2\n",
      "CHUNK e/2\n",
      "CHUNK d/2@\n",
      "CHUNK c/2\n",
      "CHUNK d/2\n",
      "CHUNK B/2\n",
      "CHUNK A/2\n",
      "CHUNK G/2\n",
      "CHUNK ^F/2\n",
      "CHUNK E/2\n",
      "CHUNK D/2@\n",
      "CHUNK ^F/2\n",
      "CHUNK A/2\n",
      "CHUNK D/2\n",
      "CHUNK B/2\n",
      "CHUNK D/2\n",
      "CHUNK ^F/2\n",
      "CHUNK D/2\n",
      "CHUNK B/2@\n",
      "CHUNK G/2\n",
      "CHUNK B/2\n",
      "CHUNK d/2\n",
      "CHUNK g/2\n",
      "CHUNK d/2\n",
      "CHUNK B/2\n",
      "CHUNK d/2\n",
      "CHUNK c/2@\n",
      "CHUNK d/2\n",
      "CHUNK c/2\n",
      "CHUNK A/2\n",
      "CHUNK c/2\n",
      "CHUNK d/2\n",
      "CHUNK c/2\n",
      "CHUNK A/2\n",
      "CHUNK B/2@\n",
      "CHUNK A/2\n",
      "CHUNK G/2\n",
      "CHUNK ^F/2\n",
      "CHUNK E/2\n",
      "CHUNK D/2\n",
      "CHUNK B\n",
      "CHUNK A@\n",
      "CHUNK D/2\n",
      "CHUNK ^F/2\n",
      "CHUNK D\n",
      "CHUNK D/2\n",
      "CHUNK ^F/2\n",
      "CHUNK G/2@\n",
      "CHUNK B/2\n",
      "CHUNK d/2\n",
      "CHUNK B/2\n",
      "CHUNK e/2\n",
      "CHUNK c/2\n",
      "CHUNK A/2\n",
      "CHUNK B/2\n",
      "CHUNK d@\n",
      "CHUNK d\n",
      "CHUNK d\n",
      "REPEAT 0 76\n",
      "CHUNK (2g/2\n",
      "CHUNK G/2\n",
      "CHUNK e/2\n",
      "CHUNK g/2\n",
      "CHUNK ^f/2@\n",
      "CHUNK d/2\n",
      "CHUNK ^f/2\n",
      "CHUNK a/2\n",
      "CHUNK g/2\n",
      "CHUNK ^f/2\n",
      "CHUNK g/2\n",
      "CHUNK e/2\n",
      "CHUNK ^f/2@\n",
      "CHUNK d/2\n",
      "CHUNK ^f/2\n",
      "CHUNK a/2\n",
      "CHUNK g/2\n",
      "CHUNK e/2\n",
      "CHUNK c/2\n",
      "CHUNK e/2\n",
      "CHUNK d/2@\n",
      "CHUNK c/2\n",
      "CHUNK d/2\n",
      "CHUNK B/2\n",
      "CHUNK A/2\n",
      "CHUNK G/2\n",
      "CHUNK ^F/2\n",
      "CHUNK E/2\n",
      "CHUNK D/2@\n",
      "CHUNK ^F/2\n",
      "CHUNK A/2\n",
      "CHUNK D/2\n",
      "CHUNK B/2\n",
      "CHUNK D/2\n",
      "CHUNK ^F/2\n",
      "CHUNK D/2\n",
      "CHUNK B/2@\n",
      "CHUNK G/2\n",
      "CHUNK B/2\n",
      "CHUNK d/2\n",
      "CHUNK g/2\n",
      "CHUNK d/2\n",
      "CHUNK B/2\n",
      "CHUNK d/2\n",
      "CHUNK c/2@\n",
      "CHUNK d/2\n",
      "CHUNK c/2\n",
      "CHUNK A/2\n",
      "CHUNK c/2\n",
      "CHUNK d/2\n",
      "CHUNK c/2\n",
      "CHUNK A/2\n",
      "CHUNK B/2@\n",
      "CHUNK A/2\n",
      "CHUNK G/2\n",
      "CHUNK ^F/2\n",
      "CHUNK E/2\n",
      "CHUNK D/2\n",
      "CHUNK B\n",
      "CHUNK A@\n",
      "CHUNK D/2\n",
      "CHUNK ^F/2\n",
      "CHUNK D\n",
      "CHUNK D/2\n",
      "CHUNK ^F/2\n",
      "CHUNK G/2@\n",
      "CHUNK B/2\n",
      "CHUNK d/2\n",
      "CHUNK B/2\n",
      "CHUNK e/2\n",
      "CHUNK c/2\n",
      "CHUNK A/2\n",
      "CHUNK B/2\n",
      "CHUNK d@\n",
      "CHUNK d\n",
      "CHUNK d\n",
      "CHUNK ^f/2\n",
      "CHUNK g/2\n",
      "CHUNK a@\n",
      "CHUNK ^f\n",
      "CHUNK d3/2\n",
      "CHUNK d/2\n",
      "CHUNK A@\n",
      "CHUNK ^F\n",
      "CHUNK A\n",
      "CHUNK d\n",
      "CHUNK c/2@\n",
      "CHUNK e/2\n",
      "CHUNK c\n",
      "CHUNK A\n",
      "CHUNK ^F/2\n",
      "CHUNK E/2\n",
      "CHUNK D/2@\n",
      "CHUNK E/2\n",
      "CHUNK ^F/2\n",
      "CHUNK G/2\n",
      "CHUNK A\n",
      "CHUNK B\n",
      "CHUNK D@\n",
      "CHUNK ^F/2\n",
      "CHUNK G/2\n",
      "CHUNK ^F\n",
      "CHUNK E\n",
      "CHUNK ^F3/2@\n",
      "CHUNK D/2\n",
      "CHUNK D\n",
      "CHUNK D\n",
      "CHUNK ^F@\n",
      "CHUNK D\n",
      "CHUNK -^F@\n",
      "CHUNK E\n",
      "CHUNK A2\n",
      "CHUNK ^F@\n",
      "CHUNK A\n",
      "CHUNK ^F\n",
      "CHUNK A\n",
      "CHUNK G/2@\n",
      "CHUNK ^F/2\n",
      "CHUNK G/2\n",
      "CHUNK B/2\n",
      "CHUNK d/2\n",
      "CHUNK B/2\n",
      "CHUNK G/2\n",
      "CHUNK B/2\n",
      "CHUNK d/2@\n",
      "CHUNK B/2\n",
      "CHUNK G/2\n",
      "CHUNK B/2\n",
      "CHUNK d/2\n",
      "CHUNK B/2\n",
      "CHUNK A/2\n",
      "CHUNK B/2\n",
      "CHUNK G/2@\n",
      "CHUNK B/2\n",
      "CHUNK G/2\n",
      "CHUNK B/2\n",
      "CHUNK A/2\n",
      "CHUNK ^F/2\n",
      "CHUNK D/2\n",
      "CHUNK ^F/2\n",
      "CHUNK G/2@\n",
      "CHUNK d/2\n",
      "CHUNK A/2\n",
      "CHUNK G/2\n",
      "CHUNK A/2\n",
      "CHUNK B/2\n",
      "CHUNK d/2\n",
      "CHUNK c/2@\n",
      "CHUNK A/2\n",
      "CHUNK B/2\n",
      "CHUNK G/2\n",
      "CHUNK A/2\n",
      "CHUNK c/2\n",
      "CHUNK B/2\n",
      "CHUNK A/2\n",
      "CHUNK G/2@\n",
      "CHUNK A/2\n",
      "CHUNK B/2\n",
      "CHUNK c/2\n",
      "CHUNK d/2\n",
      "CHUNK e/2\n",
      "CHUNK d/2\n",
      "CHUNK c/2\n",
      "CHUNK B/2@\n",
      "CHUNK d/2\n",
      "CHUNK e/2\n",
      "CHUNK ^f/2\n",
      "CHUNK g/2\n",
      "CHUNK ^f/2\n",
      "CHUNK e/2\n",
      "CHUNK d/2\n",
      "CHUNK c/2@\n",
      "CHUNK d/2\n",
      "CHUNK e/2\n",
      "CHUNK ^f/2\n",
      "CHUNK g/2\n",
      "CHUNK ^f/2\n",
      "CHUNK g/2\n",
      "CHUNK e/2\n",
      "CHUNK d/2@\n",
      "CHUNK B/2\n",
      "CHUNK e/2\n",
      "CHUNK d/2\n",
      "CHUNK B\n",
      "CHUNK d/2\n",
      "CHUNK c/2\n",
      "CHUNK B/2@\n",
      "CHUNK G/2\n",
      "CHUNK B/2\n",
      "CHUNK d/2\n",
      "CHUNK g\n",
      "CHUNK d\n",
      "CHUNK B/2@\n",
      "CHUNK d/2\n",
      "CHUNK e\n",
      "CHUNK d\n",
      "CHUNK d/2\n",
      "CHUNK c/2\n",
      "CHUNK B/2@\n",
      "CHUNK d/2\n",
      "CHUNK g/2\n",
      "CHUNK d/2\n",
      "CHUNK c/2\n",
      "CHUNK d/2\n",
      "CHUNK e/2\n",
      "CHUNK ^f/2\n",
      "CHUNK d/2@\n",
      "CHUNK c/2\n",
      "CHUNK B/2\n",
      "CHUNK A/2\n",
      "CHUNK d@\n",
      "CHUNK d\n",
      "CHUNK d\n",
      "REPEAT 76 213\n",
      "CHUNK ^f/2\n",
      "CHUNK g/2\n",
      "CHUNK a@\n",
      "CHUNK ^f\n",
      "CHUNK d3/2\n",
      "CHUNK d/2\n",
      "CHUNK A@\n",
      "CHUNK ^F\n",
      "CHUNK A\n",
      "CHUNK d\n",
      "CHUNK c/2@\n",
      "CHUNK e/2\n",
      "CHUNK c\n",
      "CHUNK A\n",
      "CHUNK ^F/2\n",
      "CHUNK E/2\n",
      "CHUNK D/2@\n",
      "CHUNK E/2\n",
      "CHUNK ^F/2\n",
      "CHUNK G/2\n",
      "CHUNK A\n",
      "CHUNK B\n",
      "CHUNK D@\n",
      "CHUNK ^F/2\n",
      "CHUNK G/2\n",
      "CHUNK ^F\n",
      "CHUNK E\n",
      "CHUNK ^F3/2@\n",
      "CHUNK D/2\n",
      "CHUNK D\n",
      "CHUNK D\n",
      "CHUNK ^F@\n",
      "CHUNK D\n",
      "CHUNK -^F@\n",
      "CHUNK E\n",
      "CHUNK A2\n",
      "CHUNK ^F@\n",
      "CHUNK A\n",
      "CHUNK ^F\n",
      "CHUNK A\n",
      "CHUNK G/2@\n",
      "CHUNK ^F/2\n",
      "CHUNK G/2\n",
      "CHUNK B/2\n",
      "CHUNK d/2\n",
      "CHUNK B/2\n",
      "CHUNK G/2\n",
      "CHUNK B/2\n",
      "CHUNK d/2@\n",
      "CHUNK B/2\n",
      "CHUNK G/2\n",
      "CHUNK B/2\n",
      "CHUNK d/2\n",
      "CHUNK B/2\n",
      "CHUNK A/2\n",
      "CHUNK B/2\n",
      "CHUNK G/2@\n",
      "CHUNK B/2\n",
      "CHUNK G/2\n",
      "CHUNK B/2\n",
      "CHUNK A/2\n",
      "CHUNK ^F/2\n",
      "CHUNK D/2\n",
      "CHUNK ^F/2\n",
      "CHUNK G/2@\n",
      "CHUNK d/2\n",
      "CHUNK A/2\n",
      "CHUNK G/2\n",
      "CHUNK A/2\n",
      "CHUNK B/2\n",
      "CHUNK d/2\n",
      "CHUNK c/2@\n",
      "CHUNK A/2\n",
      "CHUNK B/2\n",
      "CHUNK G/2\n",
      "CHUNK A/2\n",
      "CHUNK c/2\n",
      "CHUNK B/2\n",
      "CHUNK A/2\n",
      "CHUNK G/2@\n",
      "CHUNK A/2\n",
      "CHUNK B/2\n",
      "CHUNK c/2\n",
      "CHUNK d/2\n",
      "CHUNK e/2\n",
      "CHUNK d/2\n",
      "CHUNK c/2\n",
      "CHUNK B/2@\n",
      "CHUNK d/2\n",
      "CHUNK e/2\n",
      "CHUNK ^f/2\n",
      "CHUNK g/2\n",
      "CHUNK ^f/2\n",
      "CHUNK e/2\n",
      "CHUNK d/2\n",
      "CHUNK c/2@\n",
      "CHUNK d/2\n",
      "CHUNK e/2\n",
      "CHUNK ^f/2\n",
      "CHUNK g/2\n",
      "CHUNK ^f/2\n",
      "CHUNK g/2\n",
      "CHUNK e/2\n",
      "CHUNK d/2@\n",
      "CHUNK B/2\n",
      "CHUNK e/2\n",
      "CHUNK d/2\n",
      "CHUNK B\n",
      "CHUNK d/2\n",
      "CHUNK c/2\n",
      "CHUNK B/2@\n",
      "CHUNK G/2\n",
      "CHUNK B/2\n",
      "CHUNK d/2\n",
      "CHUNK g\n",
      "CHUNK d\n",
      "CHUNK B/2@\n",
      "CHUNK d/2\n",
      "CHUNK e\n",
      "CHUNK d\n",
      "CHUNK d/2\n",
      "CHUNK c/2\n",
      "CHUNK B/2@\n",
      "CHUNK d/2\n",
      "CHUNK g/2\n",
      "CHUNK d/2\n",
      "CHUNK c/2\n",
      "CHUNK d/2\n",
      "CHUNK e/2\n",
      "CHUNK ^f/2\n",
      "CHUNK d/2@\n",
      "CHUNK c/2\n",
      "CHUNK B/2\n",
      "CHUNK A/2\n",
      "CHUNK d@\n",
      "CHUNK d\n",
      "CHUNK d\n"
     ]
    }
   ],
   "source": [
    "def abc_get_note_chunk(strin):\n",
    "    index = 0\n",
    "    insideQuote = False\n",
    "    \n",
    "    \n",
    "    if len(strin)>1:\n",
    "        if (strin[:2] == '|:' or strin[:2] == ':|'):\n",
    "            return strin[:2], strin[2:]\n",
    "        if strin[:2] == '(3':\n",
    "            return strin[:2], strin[2:]\n",
    "    if len(strin)>0 and strin[0] == ':':\n",
    "        return strin[:1], strin[1:]\n",
    "                         \n",
    "    while index < len(strin) and not strin[index] in 'zabcdefgABCDEFG':\n",
    "        if strin[index] == '\"':\n",
    "            insideQuote = True\n",
    "        index+=1\n",
    "    if index >= len(strin):\n",
    "        return strin, ''\n",
    "    endex = index+1\n",
    "    \n",
    "    canWaste = False\n",
    "    while (endex < len(strin) and strin[endex] in ',/0123456789im#+\"') or (insideQuote and canWaste) or ('dim' in strin and strin[endex]=='d'):\n",
    "        if not strin[endex] in ',/0123456789dim#+\"':\n",
    "            canWaste = False\n",
    "        if strin[endex] == '/':\n",
    "            canWaste = True\n",
    "        if strin[endex] == '\"' and insideQuote:\n",
    "            insideQuote = False\n",
    "        endex +=1\n",
    "    if endex >= len(strin):\n",
    "        return strin, ''\n",
    "    \n",
    "    return strin[:endex], strin[endex:]\n",
    "\n",
    "\n",
    "diversity = .2\n",
    "\n",
    "start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "# sentence = 'K:C\\nEDD|CDE|DCC|C3|C3|B,3|B,3|A,3|EDD|\\n'\n",
    "# while len(sentence) < maxlen: \n",
    "#     sentence = ' '+sentence\n",
    "sentence = text[start_index\n",
    "                : start_index + maxlen]\n",
    "\n",
    "while not 'k:' in sentence.lower():\n",
    "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "    sentence = text[start_index: start_index + maxlen]\n",
    "generated = ''\n",
    "# print('----- Generating with seed: \"' + sentence + '\"')\n",
    "#     sys.stdout.write(generated)\n",
    "\n",
    "bigstr = sentence\n",
    "justEncounteredKey = False\n",
    "hasEncounteredKey = False\n",
    "length = 0\n",
    "while length<400 or not justEncounteredKey:\n",
    "    justEncounteredKey = False\n",
    "    if hasEncounteredKey:\n",
    "        length+=1\n",
    "    x_pred = np.zeros((1, maxlen, len(chars)))\n",
    "    for t, char in enumerate(sentence):\n",
    "        x_pred[0, t, char_indices[char]] = 1.\n",
    "\n",
    "    preds = model2.predict(x_pred, verbose=0)[0]\n",
    "#     print(preds)\n",
    "    next_index = sample(preds, diversity)\n",
    "    next_char = indices_char[next_index]\n",
    "\n",
    "    sentence = sentence[1:] + next_char\n",
    "    if hasEncounteredKey:\n",
    "        bigstr = bigstr + next_char\n",
    "    if next_char == 'K' or next_char=='P':\n",
    "        justEncounteredKey = True\n",
    "        hasEncounteredKey = True\n",
    "generated += sentence\n",
    "# print(sentence)\n",
    "print(bigstr)\n",
    "\n",
    "bigstr = bigstr.replace('::', ':||:')\n",
    "\n",
    "lines = bigstr.split('\\n')\n",
    "\n",
    "# ['a': 'a']\n",
    "sharpkeys = ['g','d','a', 'e', 'b']\n",
    "sharps = ['f', 'c', 'g', 'd', 'a']\n",
    "flatkeys = ['f']\n",
    "flats = ['b']\n",
    "\n",
    "\n",
    "'''\n",
    "TODO: include more support for more exotic keys\n",
    "'''\n",
    "\n",
    "def cleanChunk(chunk,key):\n",
    "    chunk = chunk.replace(' ','').replace('\\\\','').replace(':','')\n",
    "    if key.lower() in sharpkeys:\n",
    "        for note in sharps[:sharpkeys.index(key.lower())+1]:\n",
    "            chunk = chunk.replace(note, '^'+note)\n",
    "            chunk = chunk.replace(note.upper(), '^'+note.upper())\n",
    "    if key.lower() in flatkeys:\n",
    "        for note in flats[:flatkeys.index(key.lower())+1]:\n",
    "            chunk = chunk.replace(note, '_'+note)       \n",
    "            chunk = chunk.replace(note.upper(), '_'+note.upper())\n",
    "    return chunk\n",
    "\n",
    "key = 'c'\n",
    "                         \n",
    "chunkArr = []\n",
    "placeOfLastRepeat = 0\n",
    "                     \n",
    "vol = False\n",
    "for line in lines:\n",
    "    if 'k:' in line.lower():\n",
    "        key = line[len(line)-1]\n",
    "    if 'p:' in line.lower():\n",
    "        placeOfLastRepeat = len(chunkArr)\n",
    "    if '|' in line:\n",
    "        while len(line)>0:\n",
    "            chunk, line = abc_get_note_chunk(line)\n",
    "            if chunk == '|:':\n",
    "                placeOfLastRepeat = len(chunkArr)\n",
    "                continue\n",
    "            elif chunk == ':' or chunk == ':|':\n",
    "                print(\"REPEAT\",placeOfLastRepeat,len(chunkArr))\n",
    "#                 for i in range(10):\n",
    "#                     ESPSerial.write(str.encode('c'+\"&\"))\n",
    "                for i in range(placeOfLastRepeat, len(chunkArr),1):\n",
    "                    ESPSerial.write(str.encode(chunkArr[i]+\"&\"))\n",
    "                    print(\"CHUNK\",chunkArr[i])\n",
    "                    time.sleep(.05)\n",
    "                continue\n",
    "                \n",
    "                vol = True\n",
    "            elif chunk=='(3':\n",
    "                for i in range(3):\n",
    "                    chunk, line=abc_get_note_chunk(line)\n",
    "                    chunk = '2'+cleanChunk(chunk,key)+'/3'\n",
    "                    \n",
    "                    if(not key=='c'):\n",
    "                        if vol:\n",
    "                            chunk = chunk+'@'\n",
    "                            vol=False\n",
    "                        chunkArr.append(chunk)\n",
    "                        ESPSerial.write(str.encode(chunk+'&'))\n",
    "                        print(\"CHUNK\",chunk)\n",
    "                continue\n",
    "            chunk = cleanChunk(chunk,key)\n",
    "            \n",
    "            if(not key=='c' and '|' in chunk):\n",
    "                vol = True\n",
    "\n",
    "            chunk = chunk.replace('|','')\n",
    "            if(not key=='c' and not '\"' in chunk and len(chunk)>0):\n",
    "                if vol:\n",
    "                    chunk = chunk+'@'\n",
    "                    vol = False\n",
    "                chunkArr.append(chunk)\n",
    "                ESPSerial.write(str.encode(chunk+\"&\"))\n",
    "                print(\"CHUNK\",chunk)\n",
    "\n",
    "                time.sleep(.05)\n",
    "\n",
    "# time.sleep(2)\n",
    "# ESPSerial.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "ESPSerial.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ESPSerial = serial.Serial('com4',115200)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'abc_get_note_chunk' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-7068851c0896>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'c'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mwhile\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m>\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mchunk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mline\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mabc_get_note_chunk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunk\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'|:'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mplaceOfLastRepeat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchunkArr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'abc_get_note_chunk' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "## TWINKLE TWINKLE\n",
    "\n",
    "line = \"CCG/2G/2G/2G/2AA(3GGG FF EE D/2D/2D/2D/2 C2\"\n",
    "key='c'\n",
    "while len(line)>0:\n",
    "    chunk, line = abc_get_note_chunk(line)\n",
    "    if chunk == '|:':\n",
    "        placeOfLastRepeat = len(chunkArr)\n",
    "        continue\n",
    "    elif chunk == ':' or chunk == ':|':\n",
    "        print(\"REPEAT\",placeOfLastRepeat,len(chunkArr))\n",
    "#                 for i in range(10):\n",
    "#                     ESPSerial.write(str.encode('c'+\"&\"))\n",
    "        for i in range(placeOfLastRepeat, len(chunkArr),1):\n",
    "            ESPSerial.write(str.encode(chunkArr[i]+\"&\"))\n",
    "            print(\"CHUNK\",chunkArr[i])\n",
    "            time.sleep(.05)\n",
    "        continue\n",
    "\n",
    "        vol = True\n",
    "    elif chunk=='(3':\n",
    "        for i in range(3):\n",
    "            chunk, line=abc_get_note_chunk(line)\n",
    "            chunk = '2'+cleanChunk(chunk,key)+'/3'\n",
    "\n",
    "            if(not key=='dc'):\n",
    "                if vol:\n",
    "                    chunk = chunk+'@'\n",
    "                    vol=False\n",
    "                chunkArr.append(chunk)\n",
    "                ESPSerial.write(str.encode(chunk+'&'))\n",
    "                print(\"CHUNK\",chunk)\n",
    "        continue\n",
    "    chunk = cleanChunk(chunk,key)\n",
    "\n",
    "    if(not key=='dc' and '|' in chunk):\n",
    "        vol = True\n",
    "\n",
    "        \n",
    "    chunk = chunk.replace('|','')\n",
    "    if(not key=='dc' and not '\"' in chunk and len(chunk)>0):\n",
    "        if vol:\n",
    "            chunk = chunk+'@'\n",
    "            vol = False\n",
    "        chunkArr.append(chunk)\n",
    "        ESPSerial.write(str.encode(chunk+\"&\"))\n",
    "        print(\"CHUNK\",chunk)\n",
    "        \n",
    "        \n",
    "\n",
    "        time.sleep(.04)\n",
    "\n",
    "# time.sleep(2)        \n",
    "\n",
    "# ESPSerial.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
